{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "import io\n",
    "from urllib.request import urlopen\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from nerus import load_nerus\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cdb50c78a85c9ca3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cdb50c78a85c9ca3\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f02671bb0d4aadb403cb13059cabeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9316\n",
      "Test size: 2329\n"
     ]
    }
   ],
   "source": [
    "NERUS_PATH = \"nerus_lenta.conllu.gz\"\n",
    "N_DOCS = 1000\n",
    "dataset_words = []\n",
    "dataset_tags = []\n",
    "ctr = 0\n",
    "for doc in tqdm(load_nerus(NERUS_PATH), total=N_DOCS):\n",
    "    if ctr == N_DOCS:\n",
    "        break\n",
    "    for sent in doc.sents:\n",
    "        dataset_words.append([x.text for x in sent.tokens])\n",
    "        dataset_tags.append([x.pos for x in sent.tokens])\n",
    "    ctr += 1\n",
    "    \n",
    "\n",
    "\n",
    "train_words, train_tags = dataset_words[:int(len(dataset_words) * 0.8)], dataset_tags[:int(len(dataset_words) * 0.8)]\n",
    "# val_s, val_tags = dataset_words[int(len(dataset_words) * 0.75):int(len(dataset_words) * 0.85)], dataset_tags[int(len(dataset_words) * 0.75):int(len(dataset_words) * 0.85)]\n",
    "test_words, test_tags = dataset_words[int(len(dataset_words) * 0.8):], dataset_tags[int(len(dataset_words) * 0.8):]\n",
    "print('Train size:', len(train_words))\n",
    "# print('Val size:', len(val_sents))\n",
    "print('Test size:', len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset, loss_function, delimeter = 100, batch_size=64, exp_number = 0):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "        self.exp_number = exp_number\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar(f'LOSS/train{self.exp_number}', loss, self.step)\n",
    "        \n",
    "        if self.step % self.delimeter == 0 or self.step == 1949 or self.step == 10:\n",
    "            \n",
    "            self.writer.add_graph(model, self.dataset[0][0].view(1,1,28,28).to(model.device))\n",
    "            \n",
    "            batch_generator = torch.utils.data.DataLoader(dataset = self.dataset, \n",
    "                                                          batch_size=self.batch_size)\n",
    "            \n",
    "            pred = []\n",
    "            real = []\n",
    "            test_loss = 0\n",
    "            for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "                x_batch = x_batch.to(model.device)\n",
    "                y_batch = y_batch.to(model.device)\n",
    "\n",
    "                output = model(x_batch)\n",
    "\n",
    "                test_loss += self.loss_function(output, y_batch).cpu().item()*len(x_batch)\n",
    "\n",
    "                pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "                real.extend(y_batch.cpu().numpy().tolist())\n",
    "            \n",
    "            test_loss /= len(self.dataset)\n",
    "            \n",
    "            self.writer.add_scalar(f'LOSS/test{self.exp_number}', test_loss, self.step)\n",
    "            self.writer.add_text(f'REPORT/test{self.exp_number}', str(classification_report(real, pred)), self.step)\n",
    "          \n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'<PAD>':0, '<UNK>': 1, '<START>': 2, '<FINISH>': 3}\n",
    "idx2char = {0: '<PAD>', 1: '<UNK>', 2: '<START>', 3: '<FINISH>'}\n",
    "for words in train_words:\n",
    "    for word in words:\n",
    "        word2idx[word] = len(word2idx)\n",
    "        idx2char[word2idx[word]] = word\n",
    "\n",
    "tag2idx = {'[PAD]' : 0, '[CLS]' : 1, '[SEP]' : 2}\n",
    "for tags in train_tags:\n",
    "    for tag in tags:\n",
    "        tag2idx[tag] = tag2idx.get(tag, tag2idx.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "    def __init__(self,\n",
    "                 vocab_dim,\n",
    "                 emb_dim = 10, \n",
    "                 hidden_dim = 10,\n",
    "                 num_layers = 3,\n",
    "                 bidirectional = False):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_direction = int(bidirectional + 1)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, emb_dim)\n",
    "\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            emb_dim, hidden_dim, num_layers, bidirectional = bidirectional)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.embedding(input)\n",
    "        # print(\"BBBBBBBBBBBBB\")\n",
    "        input = torch.transpose(input, 0, 1)\n",
    "        d, (h, c) = self.encoder(input)\n",
    "        return d, torch.transpose(h, 0, 1) , torch.transpose(c, 0, 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_dim,\n",
    "                 output_dim,\n",
    "                 emb_dim = 10, \n",
    "                 hidden_dim = 10,\n",
    "                 num_layers = 3,\n",
    "                 bidirectional = False):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_direction = int(bidirectional + 1)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, self.emb_dim)\n",
    "\n",
    "        self.decoder = torch.nn.LSTM(\n",
    "            emb_dim, hidden_dim, num_layers, bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = torch.nn.Linear(\n",
    "            self.num_direction*hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, real=None, h = None, c = None, max_len = 50):\n",
    "        batch_size = 1\n",
    "        if h is not None:\n",
    "            batch_size = h.shape[0]\n",
    "        if c is not None:\n",
    "            batch_size = c.shape[0]\n",
    "        if real is not None:\n",
    "            batch_size = real.shape[0]\n",
    "\n",
    "\n",
    "        if real is not None:\n",
    "            input = self.embedding(real)\n",
    "\n",
    "            if h is None:\n",
    "                h = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "            if c is None:\n",
    "                c = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "\n",
    "            input = torch.transpose(input, 0, 1)\n",
    "            h = torch.transpose(h, 0, 1)\n",
    "            c = torch.transpose(c, 0, 1)\n",
    "            d, _ = self.decoder(input, (h, c))\n",
    "            answers = self.linear(d)\n",
    "        else:\n",
    "            input = self.embedding(\n",
    "                torch.tensor(\n",
    "                    [[word2idx['<START>']] for _ in range(\n",
    "                        batch_size)]).long().to(\n",
    "                        self.device\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if h is None:\n",
    "                h = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "            if c is None:\n",
    "                c = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "\n",
    "            input = torch.transpose(input, 0, 1)\n",
    "            h = torch.transpose(h, 0, 1)\n",
    "            c = torch.transpose(c, 0, 1)\n",
    "\n",
    "            answers = torch.zeros(\n",
    "                (max_len, input.shape[1], self.output_dim)).to(\n",
    "                    self.device)\n",
    "                \n",
    "            for i in range(max_len):\n",
    "                d, (h, c) = self.decoder(input, (h, c))\n",
    "                answers[i, :, :] = self.linear(d)[0]\n",
    "                input = self.embedding(\n",
    "                    torch.argmax(answers[i:i+1, :, :], dim=-1))\n",
    "\n",
    "        return torch.transpose(answers, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(dataset, batch_size=64, shuffle=False):\n",
    "    sents, sents_tag = dataset  #tokens, tags\n",
    "    \n",
    "    PAD = word2idx['<PAD>']\n",
    "    n_samples = len(sents)\n",
    "\n",
    "    n_batches = n_samples // batch_size\n",
    "    if n_samples % batch_size != 0:\n",
    "        n_batches += 1\n",
    "        \n",
    "    # For each k yield pair x and y\n",
    "    for k in range(n_batches):\n",
    "# указываем текущии размер батча\n",
    "        this_batch_size = batch_size\n",
    "    \n",
    "# если мы выдаем последний батч, то его нужно обрезать\n",
    "        if k == n_batches - 1:\n",
    "            if n_samples % batch_size > 0:\n",
    "                this_batch_size = n_samples % batch_size\n",
    "                \n",
    "        this_sents = sents[k * batch_size : k * batch_size + this_batch_size]\n",
    "        this_tags = sents_tag[k * batch_size : k * batch_size + this_batch_size]\n",
    "        \n",
    "        token_words = [\n",
    "                       [word2idx.get(word, 0) for word in sent]\\\n",
    "                       for sent in this_sents]\n",
    "        token_tags = [\n",
    "                    #    [tag2idx.get('<START>', 0)]\\\n",
    "                       [tag2idx.get(tag, 0) for tag in tags]\\\n",
    "                    #    + [tag2idx.get('<FINISH>', 0)]\\\n",
    "                       for tags in this_tags]\n",
    "\n",
    "        List_of_length_x = [len(sent) for sent in token_words]\n",
    "        length_of_sentence_x = max(List_of_length_x)\n",
    "\n",
    "        x_arr = np.ones(shape=[this_batch_size, length_of_sentence_x])*PAD\n",
    "        y_arr = np.ones(shape=[this_batch_size, length_of_sentence_x])*PAD\n",
    "\n",
    "        for i in range(this_batch_size):\n",
    "            x_arr[i, : len(token_words[i])] = token_words[i]\n",
    "            y_arr[i, : len(token_words[i])] = token_tags[i]\n",
    "\n",
    "        x = torch.LongTensor(x_arr)\n",
    "        y = torch.LongTensor(y_arr)\n",
    "        # lengths = torch.LongTensor(List_of_length_x)\n",
    "\n",
    "        yield x, y\n",
    "        \n",
    "def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n",
    "    encoder, decoder = model\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    \n",
    "    # print(\"AAAAAAAAAAAAAAAAAAAa\")\n",
    "    d, h, c = encoder(batch_of_x.to(encoder.device))\n",
    "    output = decoder(\n",
    "        batch_of_y.to(decoder.device), \n",
    "        h=h.to(decoder.device)[:, -decoder.num_layers:, :], \n",
    "        c=c.to(decoder.device)[:, -decoder.num_layers:, :])\n",
    "\n",
    "    loss = loss_function(output[:, :-1, :].transpose(1, 2), batch_of_y.to(decoder.device)[:, 1:])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.cpu().item()\n",
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        # print('QQQ')\n",
    "        local_loss = train_on_batch(\n",
    "            model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "        train_generator.set_postfix({'train batch loss' : local_loss})\n",
    "\n",
    "        epoch_loss += local_loss*len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "    \n",
    "    return epoch_loss / total\n",
    "def trainer(count_of_epoch, \n",
    "            batch_size,\n",
    "            model,\n",
    "            dataset,\n",
    "            loss_function,\n",
    "            optimizer,):\n",
    "    iterations = tqdm(range(count_of_epoch))\n",
    "\n",
    "    for it in iterations:\n",
    "        optima = optimizer\n",
    "\n",
    "        number_of_batch = len(dataset[0]) // batch_size + (len(dataset[0]) % batch_size > 0)\n",
    "        generator = tqdm(\n",
    "            batch_generator(dataset, batch_size), \n",
    "            leave = False, total = number_of_batch)\n",
    "            \n",
    "        epoch_loss = train_epoch(\n",
    "            train_generator = generator, model = model, \n",
    "            loss_function = loss_function, \n",
    "            optimizer = optima)\n",
    "\n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = 10\n",
    "encoder = Encoder(vocab_dim=len(word2idx) + const, \n",
    "                  num_layers=2, emb_dim=100, hidden_dim=100)\n",
    "encoder.to(device)\n",
    "decoder = Decoder(vocab_dim=len(word2idx) + const, \n",
    "                  output_dim=len(tag2idx), num_layers=2, emb_dim=100, hidden_dim=100)\n",
    "decoder.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165cded6532f49fb8341680153e7eb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.744706153869629, percent: 0.3543867011727402\n"
     ]
    }
   ],
   "source": [
    "def check_quality(model, test, loss_function):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    success = 0\n",
    "    encoder, decoder = model\n",
    "    generator = tqdm(\n",
    "            batch_generator(test, 64), \n",
    "            leave = False, total = len(test[0]) // 64)\n",
    "    \n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(generator):\n",
    "        d, h, c = encoder(batch_of_x.to(encoder.device))\n",
    "        output = decoder(\n",
    "            batch_of_y.to(decoder.device), \n",
    "        h=h.to(decoder.device)[:, -decoder.num_layers:, :],\n",
    "        c=c.to(decoder.device)[:, -decoder.num_layers:, :])\n",
    "        \n",
    "        pred = torch.argmax(output, dim=-1).cpu().numpy()\n",
    "        real = batch_of_y.cpu().numpy()\n",
    "        \n",
    "        for i in range(np.shape(pred)[0]):\n",
    "            for j in range(len(pred[i])):\n",
    "                if real[i][j] == 0:\n",
    "                    break\n",
    "                elif real[i][j] == pred[i][j]:\n",
    "                    success += 1\n",
    "                cnt += 1\n",
    "\n",
    "        loss += loss_function(output[:, :-1, :].transpose(1, 2), batch_of_y.to(decoder.device)[:, 1:])\n",
    "    loss /= 64\n",
    "    \n",
    "    \n",
    "    print(f\"loss: {loss}, percent: {success / cnt * 100}\")\n",
    "    \n",
    "check_quality((encoder, decoder), (test_words, test_tags), loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae18e7b8593443b8b88ef614f8cd73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c08b71c1d4f78b8547b1ddb4aa29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2ebebddcc24399bbe5458702006d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffccea91689948bcabf109f44eef0942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2934022abd041e0aeb3644580d10d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c6e017a098477596da8d612352d5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fef59ad96449c194c9b2e7ede9b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc0bb2b99f44a07a918f9c7264b3dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def62170efab4a499b73b02e2c4091ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a3fcf5270e4312aabc19758d9e34a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d416d8ac7c7247cc9179bd15a9ef195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer(count_of_epoch = 10,\n",
    "        batch_size = 128,\n",
    "        model = (encoder, decoder),\n",
    "        dataset = (train_words, train_tags), \n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e58fc632aa54a32b7345851d3a708ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.5429189205169678, percent: 10.946945985576717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594f79d2649944b88660220d8f870a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9636504650115967, percent: 10.16996572707561\n"
     ]
    }
   ],
   "source": [
    "check_quality((encoder, decoder), (train_words[:64 * 50], train_tags[:64 * 50]), loss_function)\n",
    "check_quality((encoder, decoder), (test_words, test_tags), loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexperiment\u001b[39m(ModelClass : torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, exp_num, count_of_epoch \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     model \u001b[39m=\u001b[39m ModelClass()\n\u001b[1;32m      3\u001b[0m     model\u001b[39m.\u001b[39mto(device)   \n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def experiment(ModelClass : torch.nn.Module, exp_num, count_of_epoch = 1):\n",
    "    model = ModelClass()\n",
    "    model.to(device)   \n",
    "    \n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    def m_loss_function(x, y):\n",
    "        y -= 1\n",
    "        return loss_function(x, y)\n",
    "    \n",
    "    optimizer = torch.optim.Adam\n",
    "    \n",
    "    writer = SummaryWriter(log_dir = 'experiment')\n",
    "    call = callback(writer, (test_words, test_tags), loss_function, delimeter = 100, exp_number=exp_num)\n",
    "\n",
    "    quality = check_quality(model, test, m_loss_function)\n",
    "    print(f\"quality before training: loss={quality[0]}, success percent={quality[1]}\")\n",
    "    \n",
    "        \n",
    "    encoder = Encoder(vocab_dim=len(word2idx) + const, \n",
    "                    num_layers=2, emb_dim=100, hidden_dim=100)\n",
    "    encoder.to(device)\n",
    "    decoder = Decoder(vocab_dim=len(word2idx) + const, \n",
    "                    output_dim=len(tag2idx), num_layers=2, emb_dim=100, hidden_dim=100)\n",
    "    decoder.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "    loss_function = torch.nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n",
    "\n",
    "\n",
    "    trainer(count_of_epoch = 10,\n",
    "        batch_size = 128,\n",
    "        model = (encoder, decoder),\n",
    "        dataset = (train_words, train_tags), \n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer,\n",
    "        callback = call)\n",
    "    \n",
    "    quality = check_quality(model, test, m_loss_function)\n",
    "    print(f\"quality after training: loss={quality[0]}, success percent={quality[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый вариант"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
