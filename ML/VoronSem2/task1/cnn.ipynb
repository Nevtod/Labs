{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "import io\n",
    "from urllib.request import urlopen\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fd4f90eea25bc88d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fd4f90eea25bc88d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset, loss_function, delimeter = 100, batch_size=64, exp_number = 0):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "        self.exp_number = exp_number\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar(f'LOSS/train{self.exp_number}', loss, self.step)\n",
    "        \n",
    "        if self.step % self.delimeter == 0 or self.step == 1949 or self.step == 10:\n",
    "            \n",
    "            self.writer.add_graph(model, self.dataset[0][0].view(1,1,28,28).to(model.device))\n",
    "            \n",
    "            batch_generator = torch.utils.data.DataLoader(dataset = self.dataset, \n",
    "                                                          batch_size=self.batch_size)\n",
    "            \n",
    "            pred = []\n",
    "            real = []\n",
    "            test_loss = 0\n",
    "            for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "                x_batch = x_batch.to(model.device)\n",
    "                y_batch = y_batch.to(model.device)\n",
    "\n",
    "                output = model(x_batch)\n",
    "\n",
    "                test_loss += self.loss_function(output, y_batch).cpu().item()*len(x_batch)\n",
    "\n",
    "                pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "                real.extend(y_batch.cpu().numpy().tolist())\n",
    "            \n",
    "            test_loss /= len(self.dataset)\n",
    "            \n",
    "            self.writer.add_scalar(f'LOSS/test{self.exp_number}', test_loss, self.step)\n",
    "            self.writer.add_text(f'REPORT/test{self.exp_number}', str(classification_report(real, pred)), self.step)\n",
    "\n",
    "        # if self.step == 1949 or self.step == 10:\n",
    "        #     x = x_batch[-10:]\n",
    "        #     y = model.layers.conv1(x.to(model.device))\n",
    "        #     z = model.layers.conv2(model.layers.pool1(model.layers.relu1(y)))\n",
    "\n",
    "        #     fig = plt.figure(figsize=(30, 15))\n",
    "        #     gs = gridspec.GridSpec(10, 23)\n",
    "        #     ax = np.empty([10, 23], dtype=object)\n",
    "        #     for i in range(10):\n",
    "        #         for j in range(23):\n",
    "        #             ax[i][j] = fig.add_subplot(gs[i, j])\n",
    "        #     for i in range(len(x)):\n",
    "        #         ax[i][0].imshow(x.cpu().data[i, 0].numpy())\n",
    "        #         ax[i][0].axis(\"off\")\n",
    "        #         for j in range(1, 7):\n",
    "        #             ax[i][j].imshow(y.cpu().data[i, j-1].numpy())\n",
    "        #             ax[i][j].axis(\"off\")\n",
    "\n",
    "        #         for j in range(7, 23):\n",
    "        #             ax[i][j].imshow(z.cpu().data[i, j-7].numpy())\n",
    "        #             ax[i][j].axis(\"off\")\n",
    "        #     self.writer.add_figure('CNN/convs', fig, self.step)\n",
    "          \n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    output = model(x_batch.to(device))\n",
    "    loss = loss_function(output, y_batch.to(device))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()\n",
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer, callback = None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to(device), batch_of_y.to(device), optimizer, loss_function)\n",
    "        \n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "            \n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "    \n",
    "    return epoch_loss/total\n",
    "\n",
    "\n",
    "def trainer(count_of_epoch, \n",
    "            batch_size, \n",
    "            dataset,\n",
    "            model, \n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr = 0.001,\n",
    "            callback = None):\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    \n",
    "    iterations = tqdm(range(count_of_epoch), desc='epoch')\n",
    "    iterations.set_postfix({'train epoch loss': np.nan})\n",
    "    for it in iterations:\n",
    "        batch_generator = tqdm(\n",
    "            torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True), \n",
    "            leave=False, total=len(dataset)//batch_size+(len(dataset)%batch_size> 0))\n",
    "        \n",
    "        epoch_loss = train_epoch(train_generator=batch_generator, \n",
    "                    model=model, \n",
    "                    loss_function=loss_function, \n",
    "                    optimizer=optima, \n",
    "                    callback=callback)\n",
    "        \n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.EMNIST('./emnist', split='letters', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = datasets.EMNIST('./emnist', split='letters', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality(model, test, loss_function):\n",
    "    batch_generator = torch.utils.data.DataLoader(dataset = test, \n",
    "                                                batch_size=64)\n",
    "    pred = []\n",
    "    real = []\n",
    "    test_loss = 0\n",
    "    for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        output = model(x_batch)    \n",
    "        \n",
    "        test_loss += loss_function(output, y_batch).cpu().item() * len(x_batch)\n",
    "        pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "        real.extend(y_batch.cpu().numpy().tolist())\n",
    "        # print(\"predict:\", pred)\n",
    "        # print(\"real:\", real)\n",
    "    test_loss /= len(test)\n",
    "    loss = test_loss\n",
    "    percent = 100 * len(list(filter(lambda pair: pair[0] == pair[1], zip(pred, real)))) / len(pred)\n",
    "    return loss, percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(ModelClass : torch.nn.Module, exp_num, count_of_epoch = 1):\n",
    "    model = ModelClass()\n",
    "    model.to(device)   \n",
    "    \n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    def m_loss_function(x, y):\n",
    "        y -= 1\n",
    "        return loss_function(x, y)\n",
    "    \n",
    "    optimizer = torch.optim.Adam\n",
    "    \n",
    "    writer = SummaryWriter(log_dir = 'experiment')\n",
    "    call = callback(writer, test, m_loss_function, delimeter = 100, exp_number=exp_num)\n",
    "\n",
    "    quality = check_quality(model, test, m_loss_function)\n",
    "    print(f\"quality before training: loss={quality[0]}, success percent={quality[1]}\")\n",
    "    \n",
    "    trainer(count_of_epoch = count_of_epoch,\n",
    "        batch_size = 64,\n",
    "        dataset = train,\n",
    "        model = model, ### Качество аппроксимации до обучения\n",
    "        loss_function = m_loss_function,\n",
    "        optimizer = optimizer,\n",
    "        lr = 0.001,\n",
    "        callback = call)\n",
    "    \n",
    "    quality = check_quality(model, test, m_loss_function)\n",
    "    print(f\"quality after training: loss={quality[0]}, success percent={quality[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2605246250446025, success percent=3.8461538461538463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f842b96f993143079796e01b48ab5be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5376efa6194eb3adf84f4bc732e4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.3670731298854718, success percent=88.1826923076923\n"
     ]
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*4*4, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оставляем меньше слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2602492178403413, success percent=3.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff608675a72d4c65bc7e320f586e7195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72faf583ba94f8989e2e9ae1ec04439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.38733663987654904, success percent=87.77884615384616\n"
     ]
    }
   ],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(6*24*24, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество упало \n",
    "Добавим больше слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2601001761509822, success percent=3.8461538461538463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c337a7b950f34a338deb4d1da9d8b624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2980557f485943179799ea6e422288bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a433fbeaff6e4a6fb5ab6b961f56daf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084db5241eb340d494d2411977b057b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fab52e6f929489ba0a9791b215e567b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8181eee05dc4425487e58321a4e48f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81472d3bee264e009efe5250b3bec4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c6aec74e0d44b2bff1b9154c140c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470d41901b5e43c596b53baf1314d155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6766bdcd875540148da3308487f4b2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2e4c9bd0984721b69bcc097307197c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.371203347410147, success percent=88.34134615384616\n"
     ]
    }
   ],
   "source": [
    "class CNN2(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1 *  6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv3', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv4', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv5', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu5', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv6', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu6', torch.nn.ReLU())\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(6 * 4 * 4, 120))\n",
    "        self.layers.add_module('relu7', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu8', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN2, 2, count_of_epoch=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# качество меньше на 10% c одной эпохой и выше на 1% с 10ю эпохами\n",
    "\n",
    "Теперь оставим один relu в конце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.259963056857769, success percent=3.8461538461538463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f167365bfe234bf08f8fd12f1227c1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0bec1b392e4221949d8e0650d96700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.8229907399874468, success percent=74.73076923076923\n"
     ]
    }
   ],
   "source": [
    "class CNN3(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1 *  6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv3', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv4', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv5', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu5', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv6', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        self.layers.add_module('relu6', torch.nn.ReLU())\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(6 * 4 * 4, 120))\n",
    "        self.layers.add_module('relu7', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu8', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN3, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество ещё ниже\n",
    "Увеличим kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.261124090781579, success percent=3.8461538461538463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5baffceb974f28ae5a43b8f16c3b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76de5c47250b4eeeb12d143ac3ab8af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.385198742950765, success percent=87.60576923076923\n"
     ]
    }
   ],
   "source": [
    "class CNN4(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1 *  6, kernel_size = 10))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(6, 1 * 16, kernel_size = 10))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2))\n",
    "        # self.layers.add_module('conv3', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        # self.layers.add_module('conv4', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        # self.layers.add_module('conv5', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu5', torch.nn.ReLU())\n",
    "        # self.layers.add_module('conv6', torch.nn.Conv2d(6, 1 * 6, kernel_size = 5))\n",
    "        # self.layers.add_module('relu6', torch.nn.ReLU())\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16 * 5 * 5, 120))\n",
    "        self.layers.add_module('relu7', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu8', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN4, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество ниже, чем у базового варианта\n",
    "\n",
    "Увеличим пуллинг. Сначала уменьшим страйд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2596484184265138, success percent=3.451923076923077\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1601fe299d4749e1a6f37db2a9748ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72733ab78db54175b53df046e3bd7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.339270992072729, success percent=89.1923076923077\n"
     ]
    }
   ],
   "source": [
    "class CNN5(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN5, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*18*18, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN5, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество выросло. Не надо сжимать пуллингом данные так быстро\n",
    "Теперь увеличим ядро пуллинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2600202178955078, success percent=3.8365384615384617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09f8a114e6e4f708219299365e3165b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1def41e2bc341dd84afdbfd81afb227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.4131858579814434, success percent=86.76442307692308\n"
     ]
    }
   ],
   "source": [
    "class CNN6(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN6, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 5, stride=1))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 5, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*12*12, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN6, 6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С увеличением пуллинга качество упало"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реструктурируем сеть для уменьшения сжатия после разворачивания 3d в 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.258965319119967, success percent=3.730769230769231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b66531b1e9e4330a462361337d26177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216fcd349cf047c3a864cf25b418db62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.26302440037807595, success percent=91.66346153846153\n"
     ]
    }
   ],
   "source": [
    "class CNN7(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN7, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*18*18, 1024))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(1024, 256))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(256, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN7, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество выросло на ~3%\n",
    "# Добавим batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2635724639892576, success percent=3.581730769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b371da211144d680cfd3efe04b6f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7871b4e3edd045318db3dd9a230ebe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.5400554994436411, success percent=83.6875\n"
     ]
    }
   ],
   "source": [
    "class CNN8(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN8, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('bnorm1', torch.nn.BatchNorm2d(6))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('bnorm2', torch.nn.BatchNorm2d(16))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*18*18, 1024))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(1024, 256))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(256, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN8, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорость не возросла, хотя ожидалось обратное. Видимо вся скорость теряется на толстых линейных слоях. Качество на 10% ниже. Падение качества свидетельствует о том, что нейросеть успевает хорошо обучиться за одну эпоху и так\n",
    "\n",
    "\n",
    "Теперь добавим dropout 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2590960671351508, success percent=3.3125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dcab90ccd648c0a74ce0933394e1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c5d3f89b7540cd8db2b17e6c6139af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.2545776669867337, success percent=91.49038461538461\n"
     ]
    }
   ],
   "source": [
    "class CNN9(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN9, self).__init__()\n",
    "        \n",
    "        p = 0.1\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*18*18, 1024))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(1024, 256))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(256, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN9, 9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество немного упало.\n",
    "А если dropout 20%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality before training: loss=3.2596936240563026, success percent=3.1538461538461537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e17d33cf3044f339a74b9f11cdd4dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9972cd2473242bd8ad3393241382ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vlad/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality after training: loss=0.2547457879093977, success percent=91.53365384615384\n"
     ]
    }
   ],
   "source": [
    "class CNN10(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(CNN10, self).__init__()\n",
    "        \n",
    "        p = 0.2\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size = 5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size = 5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size = 2, stride=1))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*18*18, 1024))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(1024, 256))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('drop1', torch.nn.Dropout(p=p))\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(256, 26))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "experiment(CNN10, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы.\n",
    "\n",
    "1. C увеличением числа слоев быстро возрастает необходимое количество эпох на обучение.\n",
    "2. BatchNorm улучшения сходимости не дал\n",
    "3. Dropout тоже\n",
    "4. Характерный размер ключевых объектов на картинке - 3-5 пикселей. При поиске паттернов большего размера качество падает. При таких параметрах ядер pooling- и convolution- слоев результаты наилучшие"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
